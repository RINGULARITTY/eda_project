{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def transform_and_filter(r):\n",
    "    if r.get('verified') != True:\n",
    "        return None\n",
    "\n",
    "    new_r = r.copy()\n",
    "\n",
    "    new_r['reviewTime'] = datetime.strptime(r['reviewTime'], '%m %d, %Y').strftime('%Y%m%d')\n",
    "\n",
    "    for key in ['style', 'reviewerName', 'unixReviewTime', 'verified']:\n",
    "        new_r.pop(key, None)\n",
    "\n",
    "    if not 'reviewText' in new_r:\n",
    "        new_r['reviewText'] = ''\n",
    "\n",
    "    new_r['mark'] = new_r.pop('overall', None)\n",
    "    new_r['product'] = new_r.pop('asin', None)\n",
    "    new_r['date'] = new_r.pop('reviewTime', None)\n",
    "    new_r['user'] = new_r.pop('reviewerID', None)\n",
    "    new_r['comment'] = re.sub(' +', ' ', BeautifulSoup(new_r.pop('reviewText', None), 'html.parser').get_text().strip().replace('\\n', '').strip())\n",
    "    new_r['title'] = new_r.pop('summary', None)\n",
    "\n",
    "    if \"vote\" in new_r:\n",
    "        new_r.pop(\"vote\")\n",
    "    \n",
    "    if \"image\" in new_r:\n",
    "        new_r.pop(\"image\")\n",
    "\n",
    "    return new_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/51311621 [00:00<?, ?it/s]C:\\Users\\RINGULARITY\\AppData\\Local\\Temp\\ipykernel_12268\\2099655647.py:24: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  new_r['comment'] = re.sub(' +', ' ', BeautifulSoup(new_r.pop('reviewText', None), 'html.parser').get_text().strip().replace('\\n', '').strip())\n",
      "C:\\Users\\RINGULARITY\\AppData\\Local\\Temp\\ipykernel_12268\\2099655647.py:24: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  new_r['comment'] = re.sub(' +', ' ', BeautifulSoup(new_r.pop('reviewText', None), 'html.parser').get_text().strip().replace('\\n', '').strip())\n",
      "100%|██████████| 51311621/51311621 [1:22:25<00:00, 10376.42it/s] \n",
      " 35%|███▌      | 7361102/20994353 [09:11<17:59, 12633.75it/s]c:\\Users\\RINGULARITY\\.conda\\envs\\ml\\Lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      "100%|██████████| 20994353/20994353 [26:44<00:00, 13083.38it/s]\n",
      "100%|██████████| 12980837/12980837 [16:56<00:00, 12774.31it/s]\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32md:\\Users\\RINGULARITY\\Documents\\epita\\eda\\eda_project\\data_treatment.ipynb Cell 2\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/RINGULARITY/Documents/epita/eda/eda_project/data_treatment.ipynb#W1sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m reader \u001b[39m=\u001b[39m csv\u001b[39m.\u001b[39mreader(input_file)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/RINGULARITY/Documents/epita/eda/eda_project/data_treatment.ipynb#W1sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39mif\u001b[39;00m first_file:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Users/RINGULARITY/Documents/epita/eda/eda_project/data_treatment.ipynb#W1sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     writer\u001b[39m.\u001b[39mwriterow(\u001b[39mnext\u001b[39;49m(reader))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/RINGULARITY/Documents/epita/eda/eda_project/data_treatment.ipynb#W1sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     first_file \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/RINGULARITY/Documents/epita/eda/eda_project/data_treatment.ipynb#W1sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import rapidjson as json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def buf_count_newlines_gen(fname):\n",
    "    def _make_gen(reader):\n",
    "        b = reader(2 ** 16)\n",
    "        while b:\n",
    "            yield b\n",
    "            b = reader(2 ** 16)\n",
    "\n",
    "    with open(fname, \"rb\") as f:\n",
    "        count = sum(buf.count(b\"\\n\") for buf in _make_gen(f.raw.read))\n",
    "    return count\n",
    "\n",
    "for file_name in os.listdir(\"./data/\"):\n",
    "    if file_name.split(\".\")[-1] != \"json\":\n",
    "        continue\n",
    "    \n",
    "    file = f\"./data/{file_name}\"\n",
    "\n",
    "    lines = buf_count_newlines_gen(file)\n",
    "    data = []\n",
    "\n",
    "    with open(file) as f:\n",
    "        for i in tqdm(range(lines)):\n",
    "            line = f.readline()\n",
    "            \n",
    "            converted_line = transform_and_filter(json.loads(line))\n",
    "            if converted_line is None:\n",
    "                continue\n",
    "\n",
    "            data.append(converted_line)\n",
    "\n",
    "    pd.DataFrame(data).drop_duplicates().to_csv(f\"./data/{file_name}\"[:-4] + \"csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [12:35<00:00, 107.89s/it]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "output_file_path = \"./data/all_ratings.csv\"\n",
    "\n",
    "with open(output_file_path, 'w', newline='') as output_file:\n",
    "    writer = csv.writer(output_file)\n",
    "    \n",
    "    first_file = True\n",
    "    \n",
    "    for file_name in tqdm(os.listdir(\"./data/\")):\n",
    "        if file_name.split(\".\")[-1] != \"csv\" or file_name == output_file_path.split(\"/\")[-1]:\n",
    "            continue\n",
    "\n",
    "        file_path = f\"./data/{file_name}\"\n",
    "\n",
    "        with open(file_path, 'r') as input_file:\n",
    "            reader = csv.reader(input_file)\n",
    "            \n",
    "            try:\n",
    "                header = next(reader)\n",
    "            except StopIteration:\n",
    "                print(f\"{file_name} is empty. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            if first_file:\n",
    "                writer.writerow(header)\n",
    "                first_file = False\n",
    "            \n",
    "            for row in reader:\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "products_to_keep = set(pd.read_csv(\"./data/all_ratings.csv\", usecols=[\"product\"])[\"product\"].values)\n",
    "pattern = re.compile(r'\\$\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?')\n",
    "date_format = '%B %d, %Y'\n",
    "new_date_format = '%Y%m%d'\n",
    "\n",
    "def extract_price(s):\n",
    "    match = pattern.fullmatch(s)\n",
    "    \n",
    "    if match:\n",
    "        return float(s.replace('$', '').replace(',', ''))\n",
    "    return 0\n",
    "\n",
    "def transform_products(p):\n",
    "    asin = p[\"asin\"]\n",
    "    if not asin in products_to_keep:\n",
    "        return None\n",
    "\n",
    "    new_p = {\n",
    "        \"id\": asin,\n",
    "        \"categories\": p[\"category\"],\n",
    "        \"brand\": p[\"brand\"],\n",
    "        \"features\": p[\"feature\"],\n",
    "        \"price\": extract_price(p[\"price\"])\n",
    "    }\n",
    "    \n",
    "    for i in range(len(new_p[\"categories\"])):\n",
    "        new_p[\"categories\"][i] = re.sub(' +', ' ', BeautifulSoup(new_p[\"categories\"][i], 'html.parser').get_text().strip().replace('\\n', '').strip())\n",
    "    \n",
    "    for i in range(len(new_p[\"features\"])):\n",
    "        new_p[\"features\"][i] = re.sub(' +', ' ', BeautifulSoup(new_p[\"features\"][i], 'html.parser').get_text().strip().replace('\\n', '').strip())\n",
    "\n",
    "    try:\n",
    "        new_p[\"date\"] = datetime.strptime(p[\"date\"].strip(), '%B %d, %Y').strftime('%Y%m%d')\n",
    "    except:\n",
    "        new_p[\"date\"] = datetime(1970, 1, 1).strftime('%Y%m%d')\n",
    "\n",
    "    return new_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4071142"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(products_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./data/meta_Books.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "334697it [00:48, 7891.62it/s] C:\\Users\\RINGULARITY\\AppData\\Local\\Temp\\ipykernel_4268\\2793462468.py:36: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  new_p[\"features\"][i] = re.sub(' +', ' ', BeautifulSoup(new_p[\"features\"][i], 'html.parser').get_text().strip().replace('\\n', '').strip())\n",
      "1882482it [04:03, 1975.80it/s] C:\\Users\\RINGULARITY\\AppData\\Local\\Temp\\ipykernel_4268\\2793462468.py:33: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  new_p[\"categories\"][i] = re.sub(' +', ' ', BeautifulSoup(new_p[\"categories\"][i], 'html.parser').get_text().strip().replace('\\n', '').strip())\n",
      "2934949it [05:55, 8261.17it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2438259 496690\n",
      "Processing ./data/meta_Electronics.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "91689it [00:29, 2828.16it/s]C:\\Users\\RINGULARITY\\AppData\\Local\\Temp\\ipykernel_4268\\2793462468.py:36: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  new_p[\"features\"][i] = re.sub(' +', ' ', BeautifulSoup(new_p[\"features\"][i], 'html.parser').get_text().strip().replace('\\n', '').strip())\n",
      "786445it [05:10, 2529.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "738928 47517\n",
      "Processing ./data/meta_Sports_and_Outdoors.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "144470it [01:05, 2277.93it/s]C:\\Users\\RINGULARITY\\AppData\\Local\\Temp\\ipykernel_4268\\2793462468.py:33: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  new_p[\"categories\"][i] = re.sub(' +', ' ', BeautifulSoup(new_p[\"categories\"][i], 'html.parser').get_text().strip().replace('\\n', '').strip())\n",
      "962300it [08:01, 2000.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "924272 38028\n"
     ]
    }
   ],
   "source": [
    "import rapidjson as json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def process_file(file):\n",
    "    data = []\n",
    "    ko_lines = 0\n",
    "    with open(file) as f:\n",
    "        for line in tqdm(f):\n",
    "            transformed_data = transform_products(json.loads(line))\n",
    "            if transformed_data is not None:\n",
    "                data.append(transformed_data)\n",
    "            else:\n",
    "                ko_lines += 1\n",
    "\n",
    "    if data:\n",
    "        print(len(data), ko_lines)\n",
    "        pd.DataFrame(data).drop_duplicates(subset=[\"id\"]).to_csv(f\"./data/{os.path.basename(file).split('.')[0]}.csv\", index=False)\n",
    "\n",
    "for file in [f\"./data/{file_name}\" for file_name in os.listdir(\"./data/\") if file_name.endswith(\".json\") and \"meta\" in file_name]:\n",
    "    print(f\"Processing {file}\")\n",
    "    process_file(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:26<00:00,  1.87s/it]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "output_file_path = \"./data/all_products.csv\"\n",
    "\n",
    "with open(output_file_path, 'w', newline='') as output_file:\n",
    "    writer = csv.writer(output_file)\n",
    "    \n",
    "    first_file = True\n",
    "    \n",
    "    for file_name in tqdm(os.listdir(\"./data/\")):\n",
    "        if file_name.split(\".\")[-1] != \"csv\" or not \"meta\" in file_name:\n",
    "            continue\n",
    "\n",
    "        file_path = f\"./data/{file_name}\"\n",
    "\n",
    "        with open(file_path, 'r') as input_file:\n",
    "            reader = csv.reader(input_file)\n",
    "            \n",
    "            try:\n",
    "                header = next(reader)\n",
    "            except StopIteration:\n",
    "                print(f\"{file_name} is empty. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            if first_file:\n",
    "                writer.writerow(header)\n",
    "                first_file = False\n",
    "            \n",
    "            for row in reader:\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>categories</th>\n",
       "      <th>brand</th>\n",
       "      <th>features</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000092878</td>\n",
       "      <td>[]</td>\n",
       "      <td>Keith Graham</td>\n",
       "      <td>[]</td>\n",
       "      <td>39.94</td>\n",
       "      <td>19700101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000047715X</td>\n",
       "      <td>['Books', 'New, Used &amp; Rental Textbooks', 'Med...</td>\n",
       "      <td>Acp</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19700101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000004545</td>\n",
       "      <td>['Books', 'Arts &amp; Photography', 'Music']</td>\n",
       "      <td>Burkhard Jarisch</td>\n",
       "      <td>[]</td>\n",
       "      <td>199.99</td>\n",
       "      <td>19700101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000013765</td>\n",
       "      <td>['Books', 'Arts &amp; Photography', 'Music']</td>\n",
       "      <td>Stamps/Baxter</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19700101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000477141</td>\n",
       "      <td>['Books', 'Medical Books', 'Medicine']</td>\n",
       "      <td>ACP</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19700101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                         categories  \\\n",
       "0  0000092878                                                 []   \n",
       "1  000047715X  ['Books', 'New, Used & Rental Textbooks', 'Med...   \n",
       "2  0000004545           ['Books', 'Arts & Photography', 'Music']   \n",
       "3  0000013765           ['Books', 'Arts & Photography', 'Music']   \n",
       "4  0000477141             ['Books', 'Medical Books', 'Medicine']   \n",
       "\n",
       "              brand features   price      date  \n",
       "0      Keith Graham       []   39.94  19700101  \n",
       "1               Acp       []    0.00  19700101  \n",
       "2  Burkhard Jarisch       []  199.99  19700101  \n",
       "3     Stamps/Baxter       []    0.00  19700101  \n",
       "4               ACP       []    0.00  19700101  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "products = pd.read_csv(\"./data/all_products.csv\")\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>categories</th>\n",
       "      <th>brand</th>\n",
       "      <th>features</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000092878</td>\n",
       "      <td>[]</td>\n",
       "      <td>Keith Graham</td>\n",
       "      <td>[]</td>\n",
       "      <td>39.94</td>\n",
       "      <td>19700101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000047715X</td>\n",
       "      <td>[89792, 105868, 122041]</td>\n",
       "      <td>Acp</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19700101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000004545</td>\n",
       "      <td>[89792, 77019, 12065]</td>\n",
       "      <td>Burkhard Jarisch</td>\n",
       "      <td>[]</td>\n",
       "      <td>199.99</td>\n",
       "      <td>19700101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000013765</td>\n",
       "      <td>[89792, 77019, 12065]</td>\n",
       "      <td>Stamps/Baxter</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19700101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000477141</td>\n",
       "      <td>[89792, 25301, 6735]</td>\n",
       "      <td>ACP</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19700101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id               categories             brand features   price  \\\n",
       "0  0000092878                       []      Keith Graham       []   39.94   \n",
       "1  000047715X  [89792, 105868, 122041]               Acp       []    0.00   \n",
       "2  0000004545    [89792, 77019, 12065]  Burkhard Jarisch       []  199.99   \n",
       "3  0000013765    [89792, 77019, 12065]     Stamps/Baxter       []    0.00   \n",
       "4  0000477141     [89792, 25301, 6735]               ACP       []    0.00   \n",
       "\n",
       "       date  \n",
       "0  19700101  \n",
       "1  19700101  \n",
       "2  19700101  \n",
       "3  19700101  \n",
       "4  19700101  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import ast\n",
    "\n",
    "products['categories'] = products['categories'].apply(ast.literal_eval)\n",
    "products['features'] = products['features'].apply(ast.literal_eval)\n",
    "\n",
    "all_categories = [cat for sublist in products['categories'].tolist() for cat in sublist]\n",
    "all_features = [feature for sublist in products['features'].tolist() for feature in sublist]\n",
    "category_dict = {k: v for v, k in enumerate(set(all_categories))}\n",
    "feature_dict = {k: v for v, k in enumerate(set(all_features))}\n",
    "\n",
    "products['categories'] = products['categories'].apply(lambda x: [category_dict[cat] for cat in x])\n",
    "products['features'] = products['features'].apply(lambda x: [feature_dict[feature] for feature in x])\n",
    "\n",
    "\n",
    "with open(\"./data/categories.json\", \"w\") as f:\n",
    "    json.dump(category_dict, f)\n",
    "\n",
    "with open(\"./data/features.json\", \"w\") as f:\n",
    "    json.dump(feature_dict, f)\n",
    "\n",
    "products.to_csv(\"./data/all_products_simplified.csv\", index=False)\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mark</th>\n",
       "      <th>product</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0001713353</td>\n",
       "      <td>20161003</td>\n",
       "      <td>16201208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0001713353</td>\n",
       "      <td>20160729</td>\n",
       "      <td>225610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0001713353</td>\n",
       "      <td>20160620</td>\n",
       "      <td>18037271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0001713353</td>\n",
       "      <td>20160424</td>\n",
       "      <td>8215727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0001713353</td>\n",
       "      <td>20160214</td>\n",
       "      <td>8084801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mark     product      date      user\n",
       "0   5.0  0001713353  20161003  16201208\n",
       "1   5.0  0001713353  20160729    225610\n",
       "2   5.0  0001713353  20160620  18037271\n",
       "3   5.0  0001713353  20160424   8215727\n",
       "4   5.0  0001713353  20160214   8084801"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "ratings = pd.read_csv(\"./data/all_ratings.csv\", usecols=[\"mark\", \"product\", \"date\", \"user\"])\n",
    "\n",
    "users_dict = {k: v for v, k in enumerate(set(ratings['user']))}\n",
    "\n",
    "ratings['user'] = ratings['user'].apply(lambda x: users_dict[x])\n",
    "\n",
    "with open(\"./data/users.json\", \"w\") as f:\n",
    "    json.dump(users_dict, f)\n",
    "\n",
    "ratings.to_csv(\"./data/all_ratings_simplified.csv\", index=False)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
