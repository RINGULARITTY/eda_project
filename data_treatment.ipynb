{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retreat JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6739590,\n",
       " {'overall': 5.0,\n",
       "  'vote': '67',\n",
       "  'verified': True,\n",
       "  'reviewTime': '09 18, 1999',\n",
       "  'reviewerID': 'AAP7PPBU72QFM',\n",
       "  'asin': '0151004714',\n",
       "  'style': {'Format:': ' Hardcover'},\n",
       "  'reviewerName': 'D. C. Carrad',\n",
       "  'reviewText': 'This is the best novel I have read in 2 or 3 years.  It is everything that fiction should be -- beautifully written, engaging, well-plotted and structured.  It has several layers of meanings -- historical, family,  philosophical and more -- and blends them all skillfully and interestingly.  It makes the American grad student/writers\\' workshop \"my parents were  mean to me and then my professors were mean to me\" trivia look  childish and silly by comparison, as they are.\\nAnyone who says this is an  adolescent girl\\'s coming of age story is trivializing it.  Ignore them.  Read this book if you love literature.\\nI was particularly impressed with  this young author\\'s grasp of the meaning and texture of the lost world of  French Algeria in the 1950\\'s and \\'60\\'s...particularly poignant when read in  1999 from another ruined and abandoned French colony, amid the decaying  buildings of Phnom Penh...\\nI hope the author will write many more books  and that her publishers will bring her first novel back into print -- I  want to read it.  Thank you, Ms. Messud, for writing such a wonderful work.',\n",
       "  'summary': 'A star is born',\n",
       "  'unixReviewTime': 937612800})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rapidjson as json\n",
    "\n",
    "with open(\"data/raw_ratings.json\", \"r\") as f:\n",
    "    ratings = [json.loads(line.strip()) for line in f.readlines()]\n",
    "\n",
    "len(ratings), ratings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Keep only verified content\n",
    "- Change reviewTime into %Y%m%d format\n",
    "- Removing 'style', 'reviewerName', 'unixReviewTime', 'verified' information\n",
    "- Changing 'overall' to 'mark' and 'asin' to 'product', ...\n",
    "- Adjust reviewText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6739590 [00:00<?, ?it/s]C:\\Users\\RINGULARITY\\AppData\\Local\\Temp\\ipykernel_2212\\875312151.py:24: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  new_r['comment'] = re.sub(' +', ' ', BeautifulSoup(new_r.pop('reviewText', None), 'html.parser').get_text().strip().replace('\\n', '').strip())\n",
      "  1%|          | 37106/6739590 [00:02<07:13, 15449.92it/s]C:\\Users\\RINGULARITY\\AppData\\Local\\Temp\\ipykernel_2212\\875312151.py:24: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  new_r['comment'] = re.sub(' +', ' ', BeautifulSoup(new_r.pop('reviewText', None), 'html.parser').get_text().strip().replace('\\n', '').strip())\n",
      "100%|██████████| 6739590/6739590 [07:48<00:00, 14380.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6038416,\n",
       " {'vote': '67',\n",
       "  'mark': 5.0,\n",
       "  'product': '0151004714',\n",
       "  'date': '19990918',\n",
       "  'user': 'AAP7PPBU72QFM',\n",
       "  'comment': 'This is the best novel I have read in 2 or 3 years. It is everything that fiction should be -- beautifully written, engaging, well-plotted and structured. It has several layers of meanings -- historical, family, philosophical and more -- and blends them all skillfully and interestingly. It makes the American grad student/writers\\' workshop \"my parents were mean to me and then my professors were mean to me\" trivia look childish and silly by comparison, as they are.Anyone who says this is an adolescent girl\\'s coming of age story is trivializing it. Ignore them. Read this book if you love literature.I was particularly impressed with this young author\\'s grasp of the meaning and texture of the lost world of French Algeria in the 1950\\'s and \\'60\\'s...particularly poignant when read in 1999 from another ruined and abandoned French colony, amid the decaying buildings of Phnom Penh...I hope the author will write many more books and that her publishers will bring her first novel back into print -- I want to read it. Thank you, Ms. Messud, for writing such a wonderful work.',\n",
       "  'title': 'A star is born'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def transform_and_filter(r):\n",
    "    if r.get('verified') != True:\n",
    "        return None\n",
    "\n",
    "    new_r = r.copy()\n",
    "\n",
    "    new_r['reviewTime'] = datetime.strptime(r['reviewTime'], '%m %d, %Y').strftime('%Y%m%d')\n",
    "\n",
    "    for key in ['style', 'reviewerName', 'unixReviewTime', 'verified']:\n",
    "        new_r.pop(key, None)\n",
    "\n",
    "    if not 'reviewText' in new_r:\n",
    "        new_r['reviewText'] = ''\n",
    "\n",
    "    new_r['mark'] = new_r.pop('overall', None)\n",
    "    new_r['product'] = new_r.pop('asin', None)\n",
    "    new_r['date'] = new_r.pop('reviewTime', None)\n",
    "    new_r['user'] = new_r.pop('reviewerID', None)\n",
    "    new_r['comment'] = re.sub(' +', ' ', BeautifulSoup(new_r.pop('reviewText', None), 'html.parser').get_text().strip().replace('\\n', '').strip())\n",
    "    new_r['title'] = new_r.pop('summary', None)\n",
    "\n",
    "    return new_r\n",
    "\n",
    "filtered_ratings = [transform_and_filter(r) for r in tqdm(ratings)]\n",
    "filtered_ratings = [r for r in filtered_ratings if r is not None]\n",
    "len(filtered_ratings), filtered_ratings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/ratings.json\", \"w\") as f:\n",
    "    json.dump(filtered_ratings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rapidjson as json\n",
    "\n",
    "with open(\"data/ratings.json\", \"r\") as f:\n",
    "    filtered_ratings = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(786445,\n",
       " {'category': ['Electronics',\n",
       "   'Camera &amp; Photo',\n",
       "   'Video Surveillance',\n",
       "   'Surveillance Systems',\n",
       "   'Surveillance DVR Kits'],\n",
       "  'tech1': '',\n",
       "  'description': ['The following camera brands and models have been tested for compatibility with GV-Software.\\nGeoVision \\tACTi \\tArecont Vision \\tAXIS \\tBosch \\tCanon\\nCNB \\tD-Link \\tEtroVision \\tHikVision \\tHUNT \\tIQEye\\nJVC \\tLG \\tMOBOTIX \\tPanasonic \\tPelco \\tSamsung\\nSanyo \\tSony \\tUDP \\tVerint \\tVIVOTEK \\t \\n \\nCompatible Standard and Protocol\\nGV-System also allows for integration with all other IP video devices compatible with ONVIF(V2.0), PSIA (V1.1) standards, or RTSP protocol.\\nONVIF \\tPSIA \\tRTSP \\t  \\t  \\t \\nNote: Specifications are subject to change without notice. Every effort has been made to ensure that the information on this Web site is accurate. No liability is assumed for incidental or consequential damages arising from the use of the information or products contained herein.'],\n",
       "  'fit': '',\n",
       "  'title': 'Genuine Geovision 1 Channel 3rd Party NVR IP Software with USB Dongle Onvif PSIA',\n",
       "  'also_buy': [],\n",
       "  'tech2': '',\n",
       "  'brand': 'GeoVision',\n",
       "  'feature': ['Genuine Geovision 1 Channel NVR IP Software',\n",
       "   'Support 3rd Party IP Camera',\n",
       "   'USB Dongle'],\n",
       "  'rank': ['>#3,092 in Tools &amp; Home Improvement &gt; Safety &amp; Security &gt; Home Security &amp; Surveillance &gt; Complete Surveillance Systems &gt; Surveillance DVR Kits',\n",
       "   '>#5,010 in Tools &amp; Home Improvement &gt; Safety &amp; Security &gt; Home Security &amp; Surveillance &gt; Surveillance Video Equipment'],\n",
       "  'also_view': [],\n",
       "  'main_cat': 'Camera &amp; Photo',\n",
       "  'similar_item': '',\n",
       "  'date': 'January 28, 2014',\n",
       "  'price': '$65.00',\n",
       "  'asin': '0011300000',\n",
       "  'imageURL': ['https://images-na.ssl-images-amazon.com/images/I/411uoWa89KL._SS40_.jpg'],\n",
       "  'imageURLHighRes': ['https://images-na.ssl-images-amazon.com/images/I/411uoWa89KL.jpg']})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import rapidjson as json\n",
    "\n",
    "def load_json_line(line):\n",
    "    return json.loads(line.strip())\n",
    "\n",
    "products = []\n",
    "\n",
    "with open(\"data/raw_products.json\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    products = list(executor.map(load_json_line, lines))\n",
    "\n",
    "len(products), products[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/786445 [00:00<?, ?it/s]C:\\Users\\RINGULARITY\\AppData\\Local\\Temp\\ipykernel_2212\\3660121040.py:34: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  new_p[\"features\"][i] = re.sub(' +', ' ', BeautifulSoup(new_p[\"features\"][i], 'html.parser').get_text().strip().replace('\\n', '').strip())\n",
      "  0%|          | 1277/786445 [00:00<01:01, 12763.99it/s]C:\\Users\\RINGULARITY\\AppData\\Local\\Temp\\ipykernel_2212\\3660121040.py:31: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  new_p[\"categories\"][i] = re.sub(' +', ' ', BeautifulSoup(new_p[\"categories\"][i], 'html.parser').get_text().strip().replace('\\n', '').strip())\n",
      " 12%|█▏        | 91513/786445 [00:08<01:12, 9613.37it/s] C:\\Users\\RINGULARITY\\AppData\\Local\\Temp\\ipykernel_2212\\3660121040.py:34: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  new_p[\"features\"][i] = re.sub(' +', ' ', BeautifulSoup(new_p[\"features\"][i], 'html.parser').get_text().strip().replace('\\n', '').strip())\n",
      "100%|██████████| 786445/786445 [01:17<00:00, 10205.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(69379,\n",
       " 717066,\n",
       " {'id': '0594459451',\n",
       "  'categories': ['Electronics', 'eBook Readers & Accessories', 'Power Cables'],\n",
       "  'brand': 'Barnes &amp; Noble',\n",
       "  'features': [\"BUY MORE AND SAVE! Purchase 2 of this Item and SAVE 25% Buy 3 SAVE 30% Buy 4 SAVE 32% Here's how (restrictions apply)\"],\n",
       "  'price': 6.04,\n",
       "  'date': '20140801'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "products_to_keep = set(r[\"product\"] for r in filtered_ratings)\n",
    "pattern = re.compile(r'\\$\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?')\n",
    "date_format = '%B %d, %Y'\n",
    "new_date_format = '%Y%m%d'\n",
    "\n",
    "def extract_price(s):\n",
    "    match = pattern.fullmatch(s)\n",
    "    \n",
    "    if match:\n",
    "        return float(s.replace('$', '').replace(',', ''))\n",
    "    return None\n",
    "\n",
    "def transform_and_filter(p):\n",
    "    asin = p[\"asin\"]\n",
    "    if asin not in products_to_keep:\n",
    "        return None, asin\n",
    "\n",
    "    new_p = {\n",
    "        \"id\": asin,\n",
    "        \"categories\": p[\"category\"],\n",
    "        \"brand\": p[\"brand\"],\n",
    "        \"features\": p[\"feature\"],\n",
    "        \"price\": extract_price(p[\"price\"])\n",
    "    }\n",
    "    \n",
    "    for i in range(len(new_p[\"categories\"])):\n",
    "        new_p[\"categories\"][i] = re.sub(' +', ' ', BeautifulSoup(new_p[\"categories\"][i], 'html.parser').get_text().strip().replace('\\n', '').strip())\n",
    "    \n",
    "    for i in range(len(new_p[\"features\"])):\n",
    "        new_p[\"features\"][i] = re.sub(' +', ' ', BeautifulSoup(new_p[\"features\"][i], 'html.parser').get_text().strip().replace('\\n', '').strip())\n",
    "    \n",
    "    if new_p[\"price\"] is None:\n",
    "        return None, asin\n",
    "    \n",
    "    try:\n",
    "        new_p[\"date\"] = datetime.strptime(p[\"date\"].strip(), '%B %d, %Y').strftime('%Y%m%d')\n",
    "    except:\n",
    "        return None, asin\n",
    "\n",
    "    return new_p, 0\n",
    "\n",
    "filtered_products = []\n",
    "removed_products = []\n",
    "\n",
    "for p in tqdm(products):\n",
    "    new_p, removed = transform_and_filter(p)\n",
    "    if new_p is None:\n",
    "        removed_products.append(removed)\n",
    "    else:\n",
    "        filtered_products.append(new_p)\n",
    "\n",
    "len(filtered_products), len(removed_products), filtered_products[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0594459451',\n",
       " 'categories': [0, 1, 2],\n",
       " 'brand': 'Barnes &amp; Noble',\n",
       " 'features': [\"BUY MORE AND SAVE! Purchase 2 of this Item and SAVE 25% Buy 3 SAVE 30% Buy 4 SAVE 32% Here's how (restrictions apply)\"],\n",
       " 'price': 6.04,\n",
       " 'date': '20140801'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_categories = {}\n",
    "index = 0\n",
    "\n",
    "for d in filtered_products:\n",
    "    for category in d['categories']:\n",
    "        if category not in unique_categories:\n",
    "            unique_categories[category] = index\n",
    "            index += 1\n",
    "\n",
    "for d in filtered_products:\n",
    "    d['categories'] = [unique_categories[cat] for cat in d['categories']]\n",
    "\n",
    "with open(\"data/categories.json\", \"w\") as f:\n",
    "    json.dump(unique_categories, f)\n",
    "\n",
    "filtered_products[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0594459451',\n",
       " 'categories': [0, 1, 2],\n",
       " 'brand': 'Barnes &amp; Noble',\n",
       " 'features': [0],\n",
       " 'price': 6.04,\n",
       " 'date': '20140801'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_features = {}\n",
    "index = 0\n",
    "\n",
    "for d in filtered_products:\n",
    "    for feature in d['features']:\n",
    "        if feature not in unique_features:\n",
    "            unique_features[feature] = index\n",
    "            index += 1\n",
    "\n",
    "for d in filtered_products:\n",
    "    d['features'] = [unique_features[feat] for feat in d['features']]\n",
    "\n",
    "with open(\"data/features.json\", \"w\") as f:\n",
    "    json.dump(unique_features, f)\n",
    "\n",
    "filtered_products[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3461917, 69379)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_to_keep = set(p[\"id\"] for p in filtered_products)\n",
    "filtered_ratings = [f for f in filtered_ratings if f[\"product\"] in products_to_keep]\n",
    "\n",
    "len(filtered_ratings), len(filtered_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/ratings.json\", \"w\") as f:\n",
    "    json.dump(filtered_ratings, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
